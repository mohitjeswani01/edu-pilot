import { GoogleGenerativeAI } from "@google/generative-ai";
import OpenAI from "openai";

// Initialize both clients using the keys from your .env.local file
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const openai = new OpenAI(process.env.OPENAI_API_KEY);

/**
 * Generates content using Gemini, with a fallback to OpenAI's GPT model.
 * @param {string} prompt The prompt to send to the AI models.
 * @returns {Promise<{source: string, text: string}>} An object containing the source model and the generated text.
 */
export async function generateContentWithFallback(prompt) {
    // --- Attempt 1: Gemini ---
    try {
        console.log("Attempting to generate content with Gemini...");
        const model = genAI.getGenerativeModel({ model: "gemini-1.5-pro" });
        const result = await model.generateContent(prompt);
        const response = await result.response;
        console.log("✅ Content successfully generated by: Gemini");
        // Return the text in a consistent format
        return { source: 'Gemini', text: response.text() };
    } catch (geminiError) {
        console.error("❌ Gemini failed:", geminiError.message);
    }

    // --- Attempt 2: OpenAI (GPT) ---
    // This part will only run if the Gemini 'try' block fails
    try {
        console.log("Attempting with OpenAI (GPT)...");
        const chatCompletion = await openai.chat.completions.create({
            messages: [{ role: 'user', content: prompt }],
            model: 'gpt-3.5-turbo',
        });
        console.log("✅ Content successfully generated by: OpenAI (GPT)");
        // Return the text in a consistent format
        return { source: 'GPT', text: chatCompletion.choices[0].message.content };
    } catch (openaiError) {
        console.error("❌ OpenAI (GPT) failed:", openaiError.message);
    }

    // If both models fail, throw a final error
    throw new Error("Both Gemini and OpenAI models failed to generate content.");
}